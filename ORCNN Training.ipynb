{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog,MetadataCatalog\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "pylab.rcParams['figure.figsize'] = 10,10\n",
    "def imshow(img):\n",
    "    plt.imshow(img[:, :, [2, 1, 0]])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ORCNN on amodal datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register my amodal datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog\n",
    "dataDir='datasets/coco'\n",
    "annTrainFile='{}/annotations/COCO_amodal_train2014_with_classes_poly.json'.format(dataDir)\n",
    "imgTrainFile = '{}/train2014'.format(dataDir)\n",
    "register_coco_instances(\"amodal_coco_train\", {},annTrainFile , imgTrainFile)\n",
    "# Prepare test datasets \n",
    "annTestFile='{}/annotations/COCO_amodal_val2014_with_classes_poly.json'.format(dataDir)\n",
    "imgTestFile = '{}/val2014'.format(dataDir)\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog\n",
    "register_coco_instances(\"amodal_coco_val\", {}, annTestFile, imgTestFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = DatasetCatalog.get(\"amodal_coco_train\")\n",
    "annos = [img['annotations'] for img in dataset_dicts ]\n",
    "invisible_mask = [ obj['invisible_mask'] for img in annos for obj in img if obj.get('invisible_mask')]\n",
    "visible_mask = [ obj['visible_mask'] for img in annos for obj in img ]\n",
    "print(invisible_mask[2])\n",
    "[len(i) for i in invisible_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks : overfitting small datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register small datasets for debugging \n",
    "dataset_dicts = DatasetCatalog.get(\"amodal_coco_train\")\n",
    "import random\n",
    "imgs = random.sample(dataset_dicts,k=10)\n",
    "# imgs = dataset_dicts[:10]\n",
    "DatasetCatalog.register(\"small_amodal_test\", lambda : imgs)\n",
    "metadata = {}\n",
    "MetadataCatalog.get(\"small_amodal_test\").set(\n",
    "        image_root=\"datasets/coco/train2014\", evaluator_type=\"coco\", **metadata\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "coco_api = COCO(annTrainFile)\n",
    "cat_ids = sorted(coco_api.getCatIds())\n",
    "cats = coco_api.loadCats(cat_ids)\n",
    "# The categories in a custom json file may not be sorted.\n",
    "thing_classes = [c[\"name\"] for c in sorted(cats, key=lambda x: x[\"id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "MetadataCatalog.get(\"small_amodal_test\").set(thing_classes = thing_classes, **metadata )\n",
    "# MetadataCatalog.get(\"small_amodal_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldicts = DatasetCatalog.get(\"small_amodal_test\")\n",
    "for i in range(len(smalldicts)):\n",
    "    im = cv2.imread(smalldicts[i][\"file_name\"])\n",
    "    imshow(im[:, :, ::-1])\n",
    "    visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get(\"small_amodal_test\"), scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(smalldicts[i])\n",
    "    imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "- remove orcnnEvaluation directory everytime : create json_file for small dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_orcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"small_amodal_test\",)\n",
    "cfg.DATASETS.TEST = (\"small_amodal_test\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0015  # pick a good LR\n",
    "cfg.SOLVER.STEPS = (1300,1400)\n",
    "cfg.SOLVER.MAX_ITER = 500 \n",
    "cfg.VIS_PERIOD = 20\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80\n",
    "cfg.OUTPUT_DIR = \"orcnnCheckpoint\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set the testing threshold for this model\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "import pdb; pdb.set_trace()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=orcnnCheckpoint --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# [556865, 14]\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9   # set the testing threshold for this model\n",
    "#  evaluate its performance using AP metric implemented in COCO API.\n",
    "from detectron2.evaluation import AmodalEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = AmodalEvaluator(\"small_amodal_test\", cfg, False, output_dir=\"orcnnEvaluation\")\n",
    "val_loader = build_detection_test_loader(cfg, \"small_amodal_test\")\n",
    "# import pdb;pdb.set_trace()\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "import random\n",
    "from detectron2.data import DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9   # set the testing threshold for this model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"small_amodal_test\",)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "dataset_dicts = DatasetCatalog.get(\"small_amodal_test\")\n",
    "# for d in random.sample(dataset_dicts, 2): \n",
    "for i,d in enumerate(dataset_dicts):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get(\"small_amodal_test\"), scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d,'invisible_mask')\n",
    "    imshow(vis.get_image()[:, :, ::-1])\n",
    "#     import pdb;pdb.set_trace()\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"small_amodal_test\"), \n",
    "                   scale=0.8, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"),'pred_invisible_masks')\n",
    "    imshow(v.get_image()[:, :, ::-1])\n",
    "    cv2.imwrite('SmallSamplesVisualizing/Sample{}.png'.format(i), vis.get_image()[:, :, ::-1]) \n",
    "    cv2.imwrite('SmallSamplesVisualizing/Test{}.png'.format(i), v.get_image()[:, :, ::-1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training from a COCO-pretrained model as provided by Detectron2\n",
    "1. Finetuning : For the case of COCOA amodal the final output layers that are class-specific had to be initialized randomly as the number of classes and their semantic meaning did not fit to the number of classes of COCO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-3-395c2bcdba3c>(20)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) c\n",
      "\u001b[32m[03/01 23:14:02 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): AmodalROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (amodal_mask_head): AmodalMaskRCNNConvUpsampleHead(\n",
      "      (amodal_mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (amodal_mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (amodal_mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (amodal_mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (visible_mask_head): VisibleMaskRCNNConvUpsampleHead(\n",
      "      (visible_mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (visible_mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (visible_mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (visible_mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (invisible_mask_head): InvisibleMaskRCNNHead()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/01 23:14:03 d2.data.datasets.coco]: \u001b[0mLoaded 2276 images in COCO format from datasets/coco/annotations/COCO_amodal_train2014_with_classes_poly.json\n",
      "\u001b[32m[03/01 23:14:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2276 images left.\n",
      "\u001b[32m[03/01 23:14:03 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
      "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
      "|    person     | 2311         |   bicycle    | 21           |      car      | 279          |\n",
      "|  motorcycle   | 47           |   airplane   | 65           |      bus      | 92           |\n",
      "|     train     | 60           |    truck     | 115          |     boat      | 79           |\n",
      "| traffic light | 13           | fire hydrant | 35           |   stop sign   | 12           |\n",
      "| parking meter | 10           |    bench     | 48           |     bird      | 57           |\n",
      "|      cat      | 94           |     dog      | 100          |     horse     | 57           |\n",
      "|     sheep     | 102          |     cow      | 91           |   elephant    | 80           |\n",
      "|     bear      | 28           |    zebra     | 84           |    giraffe    | 90           |\n",
      "|   backpack    | 14           |   umbrella   | 74           |    handbag    | 26           |\n",
      "|      tie      | 9            |   suitcase   | 77           |    frisbee    | 29           |\n",
      "|     skis      | 13           |  snowboard   | 21           |  sports ball  | 36           |\n",
      "|     kite      | 49           | baseball bat | 33           | baseball gl.. | 5            |\n",
      "|  skateboard   | 41           |  surfboard   | 37           | tennis racket | 49           |\n",
      "|    bottle     | 222          |  wine glass  | 70           |      cup      | 215          |\n",
      "|     fork      | 25           |    knife     | 69           |     spoon     | 33           |\n",
      "|     bowl      | 161          |    banana    | 26           |     apple     | 34           |\n",
      "|   sandwich    | 33           |    orange    | 31           |   broccoli    | 9            |\n",
      "|    carrot     | 19           |   hot dog    | 27           |     pizza     | 60           |\n",
      "|     donut     | 70           |     cake     | 76           |     chair     | 195          |\n",
      "|     couch     | 55           | potted plant | 12           |      bed      | 26           |\n",
      "| dining table  | 34           |    toilet    | 80           |      tv       | 91           |\n",
      "|    laptop     | 74           |    mouse     | 25           |    remote     | 28           |\n",
      "|   keyboard    | 36           |  cell phone  | 38           |   microwave   | 33           |\n",
      "|     oven      | 23           |   toaster    | 5            |     sink      | 53           |\n",
      "| refrigerator  | 63           |     book     | 59           |     clock     | 39           |\n",
      "|     vase      | 45           |   scissors   | 8            |  teddy bear   | 68           |\n",
      "|  hair drier   | 0            |  toothbrush  | 10           |               |              |\n",
      "|     total     | 6763         |              |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/01 23:14:03 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/01 23:14:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/01 23:14:04 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/01 23:14:10 d2.utils.events]: \u001b[0meta: 0:07:07  iter: 19  total_loss: 1.120  loss_cls: 0.161  loss_box_reg: 0.171  loss_amodal_mask: 0.208  loss_visible_mask: 0.157  loss_invisible_mask: 0.417  loss_rpn_cls: 0.014  loss_rpn_loc: 0.010  time: 0.2973  data_time: 0.0109  lr: 0.000030  max_mem: 2883M\n",
      "\u001b[32m[03/01 23:14:17 d2.utils.events]: \u001b[0meta: 0:07:14  iter: 39  total_loss: 1.251  loss_cls: 0.182  loss_box_reg: 0.166  loss_amodal_mask: 0.269  loss_visible_mask: 0.141  loss_invisible_mask: 0.308  loss_rpn_cls: 0.024  loss_rpn_loc: 0.011  time: 0.3031  data_time: 0.0112  lr: 0.000060  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:14:23 d2.utils.events]: \u001b[0meta: 0:07:14  iter: 59  total_loss: 1.234  loss_cls: 0.198  loss_box_reg: 0.179  loss_amodal_mask: 0.275  loss_visible_mask: 0.148  loss_invisible_mask: 0.247  loss_rpn_cls: 0.018  loss_rpn_loc: 0.021  time: 0.3025  data_time: 0.0037  lr: 0.000090  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:14:28 d2.utils.events]: \u001b[0meta: 0:06:59  iter: 79  total_loss: 1.084  loss_cls: 0.145  loss_box_reg: 0.160  loss_amodal_mask: 0.263  loss_visible_mask: 0.178  loss_invisible_mask: 0.208  loss_rpn_cls: 0.014  loss_rpn_loc: 0.010  time: 0.2981  data_time: 0.0036  lr: 0.000120  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:14:35 d2.utils.events]: \u001b[0meta: 0:06:56  iter: 99  total_loss: 0.875  loss_cls: 0.179  loss_box_reg: 0.187  loss_amodal_mask: 0.188  loss_visible_mask: 0.181  loss_invisible_mask: 0.127  loss_rpn_cls: 0.015  loss_rpn_loc: 0.009  time: 0.3003  data_time: 0.0037  lr: 0.000150  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:14:41 d2.utils.events]: \u001b[0meta: 0:06:50  iter: 119  total_loss: 0.820  loss_cls: 0.158  loss_box_reg: 0.134  loss_amodal_mask: 0.164  loss_visible_mask: 0.135  loss_invisible_mask: 0.120  loss_rpn_cls: 0.014  loss_rpn_loc: 0.011  time: 0.3001  data_time: 0.0037  lr: 0.000180  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:14:46 d2.utils.events]: \u001b[0meta: 0:06:44  iter: 139  total_loss: 0.893  loss_cls: 0.163  loss_box_reg: 0.150  loss_amodal_mask: 0.219  loss_visible_mask: 0.162  loss_invisible_mask: 0.165  loss_rpn_cls: 0.016  loss_rpn_loc: 0.011  time: 0.2993  data_time: 0.0037  lr: 0.000210  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:14:52 d2.utils.events]: \u001b[0meta: 0:06:37  iter: 159  total_loss: 0.949  loss_cls: 0.134  loss_box_reg: 0.169  loss_amodal_mask: 0.209  loss_visible_mask: 0.175  loss_invisible_mask: 0.144  loss_rpn_cls: 0.015  loss_rpn_loc: 0.013  time: 0.2988  data_time: 0.0035  lr: 0.000240  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:14:58 d2.utils.events]: \u001b[0meta: 0:06:31  iter: 179  total_loss: 1.030  loss_cls: 0.170  loss_box_reg: 0.155  loss_amodal_mask: 0.202  loss_visible_mask: 0.214  loss_invisible_mask: 0.147  loss_rpn_cls: 0.013  loss_rpn_loc: 0.010  time: 0.2990  data_time: 0.0036  lr: 0.000270  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:15:05 d2.utils.events]: \u001b[0meta: 0:06:27  iter: 199  total_loss: 0.896  loss_cls: 0.163  loss_box_reg: 0.192  loss_amodal_mask: 0.200  loss_visible_mask: 0.171  loss_invisible_mask: 0.145  loss_rpn_cls: 0.013  loss_rpn_loc: 0.010  time: 0.2996  data_time: 0.0039  lr: 0.000300  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:15:11 d2.utils.events]: \u001b[0meta: 0:06:21  iter: 219  total_loss: 0.886  loss_cls: 0.148  loss_box_reg: 0.180  loss_amodal_mask: 0.206  loss_visible_mask: 0.169  loss_invisible_mask: 0.143  loss_rpn_cls: 0.009  loss_rpn_loc: 0.007  time: 0.2998  data_time: 0.0035  lr: 0.000330  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:15:17 d2.utils.events]: \u001b[0meta: 0:06:16  iter: 239  total_loss: 0.763  loss_cls: 0.167  loss_box_reg: 0.163  loss_amodal_mask: 0.169  loss_visible_mask: 0.153  loss_invisible_mask: 0.109  loss_rpn_cls: 0.007  loss_rpn_loc: 0.012  time: 0.3006  data_time: 0.0037  lr: 0.000360  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:15:23 d2.utils.events]: \u001b[0meta: 0:06:09  iter: 259  total_loss: 0.885  loss_cls: 0.136  loss_box_reg: 0.150  loss_amodal_mask: 0.221  loss_visible_mask: 0.161  loss_invisible_mask: 0.138  loss_rpn_cls: 0.007  loss_rpn_loc: 0.018  time: 0.2997  data_time: 0.0037  lr: 0.000390  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:15:29 d2.utils.events]: \u001b[0meta: 0:06:03  iter: 279  total_loss: 0.966  loss_cls: 0.099  loss_box_reg: 0.167  loss_amodal_mask: 0.217  loss_visible_mask: 0.177  loss_invisible_mask: 0.155  loss_rpn_cls: 0.009  loss_rpn_loc: 0.010  time: 0.2994  data_time: 0.0036  lr: 0.000420  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:15:35 d2.utils.events]: \u001b[0meta: 0:05:58  iter: 299  total_loss: 0.987  loss_cls: 0.176  loss_box_reg: 0.194  loss_amodal_mask: 0.206  loss_visible_mask: 0.162  loss_invisible_mask: 0.154  loss_rpn_cls: 0.009  loss_rpn_loc: 0.009  time: 0.2995  data_time: 0.0037  lr: 0.000450  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:15:40 d2.utils.events]: \u001b[0meta: 0:05:51  iter: 319  total_loss: 0.941  loss_cls: 0.123  loss_box_reg: 0.158  loss_amodal_mask: 0.207  loss_visible_mask: 0.210  loss_invisible_mask: 0.152  loss_rpn_cls: 0.007  loss_rpn_loc: 0.011  time: 0.2989  data_time: 0.0036  lr: 0.000480  max_mem: 3020M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/01 23:15:47 d2.utils.events]: \u001b[0meta: 0:05:46  iter: 339  total_loss: 1.083  loss_cls: 0.164  loss_box_reg: 0.205  loss_amodal_mask: 0.232  loss_visible_mask: 0.198  loss_invisible_mask: 0.143  loss_rpn_cls: 0.010  loss_rpn_loc: 0.019  time: 0.2997  data_time: 0.0037  lr: 0.000509  max_mem: 3020M\n",
      "\u001b[32m[03/01 23:15:53 d2.utils.events]: \u001b[0meta: 0:05:41  iter: 359  total_loss: 1.101  loss_cls: 0.190  loss_box_reg: 0.182  loss_amodal_mask: 0.237  loss_visible_mask: 0.225  loss_invisible_mask: 0.164  loss_rpn_cls: 0.009  loss_rpn_loc: 0.016  time: 0.3003  data_time: 0.0036  lr: 0.000539  max_mem: 3031M\n",
      "\u001b[32m[03/01 23:15:59 d2.utils.events]: \u001b[0meta: 0:05:34  iter: 379  total_loss: 0.940  loss_cls: 0.167  loss_box_reg: 0.224  loss_amodal_mask: 0.211  loss_visible_mask: 0.188  loss_invisible_mask: 0.151  loss_rpn_cls: 0.010  loss_rpn_loc: 0.012  time: 0.3003  data_time: 0.0035  lr: 0.000569  max_mem: 3031M\n",
      "\u001b[32m[03/01 23:16:05 d2.utils.events]: \u001b[0meta: 0:05:30  iter: 399  total_loss: 1.037  loss_cls: 0.173  loss_box_reg: 0.259  loss_amodal_mask: 0.215  loss_visible_mask: 0.185  loss_invisible_mask: 0.156  loss_rpn_cls: 0.012  loss_rpn_loc: 0.012  time: 0.3011  data_time: 0.0035  lr: 0.000599  max_mem: 3031M\n",
      "\u001b[32m[03/01 23:16:11 d2.utils.events]: \u001b[0meta: 0:05:24  iter: 419  total_loss: 0.929  loss_cls: 0.109  loss_box_reg: 0.183  loss_amodal_mask: 0.218  loss_visible_mask: 0.167  loss_invisible_mask: 0.159  loss_rpn_cls: 0.006  loss_rpn_loc: 0.013  time: 0.3011  data_time: 0.0036  lr: 0.000629  max_mem: 3031M\n",
      "\u001b[32m[03/01 23:16:17 d2.utils.events]: \u001b[0meta: 0:05:18  iter: 439  total_loss: 0.928  loss_cls: 0.164  loss_box_reg: 0.189  loss_amodal_mask: 0.194  loss_visible_mask: 0.164  loss_invisible_mask: 0.141  loss_rpn_cls: 0.013  loss_rpn_loc: 0.017  time: 0.3009  data_time: 0.0037  lr: 0.000659  max_mem: 3031M\n",
      "\u001b[32m[03/01 23:16:23 d2.utils.events]: \u001b[0meta: 0:05:12  iter: 459  total_loss: 0.971  loss_cls: 0.169  loss_box_reg: 0.178  loss_amodal_mask: 0.196  loss_visible_mask: 0.178  loss_invisible_mask: 0.112  loss_rpn_cls: 0.006  loss_rpn_loc: 0.010  time: 0.3007  data_time: 0.0039  lr: 0.000689  max_mem: 3031M\n",
      "\u001b[32m[03/01 23:16:29 d2.utils.events]: \u001b[0meta: 0:05:05  iter: 479  total_loss: 0.992  loss_cls: 0.157  loss_box_reg: 0.205  loss_amodal_mask: 0.210  loss_visible_mask: 0.222  loss_invisible_mask: 0.163  loss_rpn_cls: 0.010  loss_rpn_loc: 0.010  time: 0.3005  data_time: 0.0036  lr: 0.000719  max_mem: 3031M\n",
      "\u001b[32m[03/01 23:16:36 d2.utils.events]: \u001b[0meta: 0:05:00  iter: 499  total_loss: 0.963  loss_cls: 0.166  loss_box_reg: 0.203  loss_amodal_mask: 0.192  loss_visible_mask: 0.156  loss_invisible_mask: 0.104  loss_rpn_cls: 0.007  loss_rpn_loc: 0.010  time: 0.3014  data_time: 0.0037  lr: 0.000749  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:16:42 d2.utils.events]: \u001b[0meta: 0:04:54  iter: 519  total_loss: 0.905  loss_cls: 0.165  loss_box_reg: 0.216  loss_amodal_mask: 0.215  loss_visible_mask: 0.171  loss_invisible_mask: 0.108  loss_rpn_cls: 0.007  loss_rpn_loc: 0.011  time: 0.3016  data_time: 0.0037  lr: 0.000779  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:16:49 d2.utils.events]: \u001b[0meta: 0:04:48  iter: 539  total_loss: 0.906  loss_cls: 0.177  loss_box_reg: 0.171  loss_amodal_mask: 0.174  loss_visible_mask: 0.173  loss_invisible_mask: 0.117  loss_rpn_cls: 0.009  loss_rpn_loc: 0.010  time: 0.3023  data_time: 0.0132  lr: 0.000809  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:16:55 d2.utils.events]: \u001b[0meta: 0:04:42  iter: 559  total_loss: 0.986  loss_cls: 0.177  loss_box_reg: 0.241  loss_amodal_mask: 0.219  loss_visible_mask: 0.185  loss_invisible_mask: 0.127  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 0.3025  data_time: 0.0036  lr: 0.000839  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:17:01 d2.utils.events]: \u001b[0meta: 0:04:36  iter: 579  total_loss: 0.941  loss_cls: 0.154  loss_box_reg: 0.165  loss_amodal_mask: 0.220  loss_visible_mask: 0.190  loss_invisible_mask: 0.128  loss_rpn_cls: 0.009  loss_rpn_loc: 0.013  time: 0.3021  data_time: 0.0038  lr: 0.000869  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:17:07 d2.utils.events]: \u001b[0meta: 0:04:30  iter: 599  total_loss: 0.857  loss_cls: 0.183  loss_box_reg: 0.192  loss_amodal_mask: 0.209  loss_visible_mask: 0.197  loss_invisible_mask: 0.115  loss_rpn_cls: 0.008  loss_rpn_loc: 0.011  time: 0.3019  data_time: 0.0035  lr: 0.000899  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:17:13 d2.utils.events]: \u001b[0meta: 0:04:25  iter: 619  total_loss: 1.034  loss_cls: 0.173  loss_box_reg: 0.235  loss_amodal_mask: 0.217  loss_visible_mask: 0.204  loss_invisible_mask: 0.139  loss_rpn_cls: 0.009  loss_rpn_loc: 0.011  time: 0.3024  data_time: 0.0036  lr: 0.000929  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:17:20 d2.utils.events]: \u001b[0meta: 0:04:19  iter: 639  total_loss: 0.957  loss_cls: 0.160  loss_box_reg: 0.233  loss_amodal_mask: 0.190  loss_visible_mask: 0.176  loss_invisible_mask: 0.123  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  time: 0.3030  data_time: 0.0036  lr: 0.000959  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:17:26 d2.utils.events]: \u001b[0meta: 0:04:13  iter: 659  total_loss: 1.015  loss_cls: 0.207  loss_box_reg: 0.234  loss_amodal_mask: 0.182  loss_visible_mask: 0.189  loss_invisible_mask: 0.153  loss_rpn_cls: 0.010  loss_rpn_loc: 0.016  time: 0.3031  data_time: 0.0036  lr: 0.000989  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:17:32 d2.utils.events]: \u001b[0meta: 0:04:08  iter: 679  total_loss: 1.008  loss_cls: 0.180  loss_box_reg: 0.232  loss_amodal_mask: 0.201  loss_visible_mask: 0.190  loss_invisible_mask: 0.145  loss_rpn_cls: 0.009  loss_rpn_loc: 0.011  time: 0.3035  data_time: 0.0036  lr: 0.001019  max_mem: 3060M\n",
      "\u001b[32m[03/01 23:17:38 d2.utils.events]: \u001b[0meta: 0:04:02  iter: 699  total_loss: 0.828  loss_cls: 0.187  loss_box_reg: 0.188  loss_amodal_mask: 0.182  loss_visible_mask: 0.148  loss_invisible_mask: 0.104  loss_rpn_cls: 0.006  loss_rpn_loc: 0.008  time: 0.3037  data_time: 0.0037  lr: 0.001049  max_mem: 3094M\n",
      "\u001b[32m[03/01 23:17:44 d2.utils.events]: \u001b[0meta: 0:03:56  iter: 719  total_loss: 0.882  loss_cls: 0.166  loss_box_reg: 0.174  loss_amodal_mask: 0.195  loss_visible_mask: 0.178  loss_invisible_mask: 0.138  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  time: 0.3038  data_time: 0.0036  lr: 0.001079  max_mem: 3094M\n",
      "\u001b[32m[03/01 23:17:50 d2.utils.events]: \u001b[0meta: 0:03:50  iter: 739  total_loss: 0.890  loss_cls: 0.158  loss_box_reg: 0.196  loss_amodal_mask: 0.207  loss_visible_mask: 0.181  loss_invisible_mask: 0.127  loss_rpn_cls: 0.010  loss_rpn_loc: 0.014  time: 0.3036  data_time: 0.0038  lr: 0.001109  max_mem: 3094M\n",
      "\u001b[32m[03/01 23:17:57 d2.utils.events]: \u001b[0meta: 0:03:44  iter: 759  total_loss: 0.892  loss_cls: 0.183  loss_box_reg: 0.186  loss_amodal_mask: 0.181  loss_visible_mask: 0.215  loss_invisible_mask: 0.115  loss_rpn_cls: 0.006  loss_rpn_loc: 0.009  time: 0.3038  data_time: 0.0036  lr: 0.001139  max_mem: 3094M\n",
      "\u001b[32m[03/01 23:18:03 d2.utils.events]: \u001b[0meta: 0:03:38  iter: 779  total_loss: 0.962  loss_cls: 0.190  loss_box_reg: 0.192  loss_amodal_mask: 0.200  loss_visible_mask: 0.197  loss_invisible_mask: 0.108  loss_rpn_cls: 0.012  loss_rpn_loc: 0.019  time: 0.3038  data_time: 0.0038  lr: 0.001169  max_mem: 3094M\n",
      "\u001b[32m[03/01 23:18:09 d2.utils.events]: \u001b[0meta: 0:03:32  iter: 799  total_loss: 1.007  loss_cls: 0.203  loss_box_reg: 0.235  loss_amodal_mask: 0.196  loss_visible_mask: 0.202  loss_invisible_mask: 0.139  loss_rpn_cls: 0.015  loss_rpn_loc: 0.012  time: 0.3042  data_time: 0.0036  lr: 0.001199  max_mem: 3094M\n",
      "\u001b[32m[03/01 23:18:15 d2.utils.events]: \u001b[0meta: 0:03:26  iter: 819  total_loss: 1.019  loss_cls: 0.171  loss_box_reg: 0.217  loss_amodal_mask: 0.200  loss_visible_mask: 0.195  loss_invisible_mask: 0.121  loss_rpn_cls: 0.009  loss_rpn_loc: 0.019  time: 0.3043  data_time: 0.0037  lr: 0.001229  max_mem: 3094M\n",
      "\u001b[32m[03/01 23:18:22 d2.utils.events]: \u001b[0meta: 0:03:21  iter: 839  total_loss: 1.161  loss_cls: 0.256  loss_box_reg: 0.276  loss_amodal_mask: 0.239  loss_visible_mask: 0.185  loss_invisible_mask: 0.189  loss_rpn_cls: 0.010  loss_rpn_loc: 0.017  time: 0.3048  data_time: 0.0037  lr: 0.001259  max_mem: 3094M\n",
      "\u001b[32m[03/01 23:18:28 d2.utils.events]: \u001b[0meta: 0:03:14  iter: 859  total_loss: 0.821  loss_cls: 0.178  loss_box_reg: 0.141  loss_amodal_mask: 0.191  loss_visible_mask: 0.173  loss_invisible_mask: 0.102  loss_rpn_cls: 0.006  loss_rpn_loc: 0.009  time: 0.3044  data_time: 0.0036  lr: 0.001289  max_mem: 3094M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/01 23:18:34 d2.utils.events]: \u001b[0meta: 0:03:09  iter: 879  total_loss: 1.095  loss_cls: 0.226  loss_box_reg: 0.227  loss_amodal_mask: 0.221  loss_visible_mask: 0.172  loss_invisible_mask: 0.119  loss_rpn_cls: 0.009  loss_rpn_loc: 0.013  time: 0.3046  data_time: 0.0038  lr: 0.001319  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:18:40 d2.utils.events]: \u001b[0meta: 0:03:02  iter: 899  total_loss: 0.741  loss_cls: 0.160  loss_box_reg: 0.169  loss_amodal_mask: 0.172  loss_visible_mask: 0.170  loss_invisible_mask: 0.061  loss_rpn_cls: 0.008  loss_rpn_loc: 0.007  time: 0.3044  data_time: 0.0039  lr: 0.001349  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:18:46 d2.utils.events]: \u001b[0meta: 0:02:56  iter: 919  total_loss: 1.402  loss_cls: 0.329  loss_box_reg: 0.262  loss_amodal_mask: 0.244  loss_visible_mask: 0.219  loss_invisible_mask: 0.141  loss_rpn_cls: 0.011  loss_rpn_loc: 0.014  time: 0.3046  data_time: 0.0038  lr: 0.001379  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:18:52 d2.utils.events]: \u001b[0meta: 0:02:50  iter: 939  total_loss: 1.098  loss_cls: 0.240  loss_box_reg: 0.216  loss_amodal_mask: 0.229  loss_visible_mask: 0.206  loss_invisible_mask: 0.148  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 0.3047  data_time: 0.0036  lr: 0.001409  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:18:58 d2.utils.events]: \u001b[0meta: 0:02:44  iter: 959  total_loss: 1.010  loss_cls: 0.210  loss_box_reg: 0.228  loss_amodal_mask: 0.215  loss_visible_mask: 0.185  loss_invisible_mask: 0.125  loss_rpn_cls: 0.008  loss_rpn_loc: 0.009  time: 0.3046  data_time: 0.0036  lr: 0.001439  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:05 d2.utils.events]: \u001b[0meta: 0:02:38  iter: 979  total_loss: 1.143  loss_cls: 0.208  loss_box_reg: 0.233  loss_amodal_mask: 0.216  loss_visible_mask: 0.213  loss_invisible_mask: 0.124  loss_rpn_cls: 0.009  loss_rpn_loc: 0.017  time: 0.3047  data_time: 0.0035  lr: 0.001469  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:11 d2.utils.events]: \u001b[0meta: 0:02:32  iter: 999  total_loss: 1.036  loss_cls: 0.237  loss_box_reg: 0.202  loss_amodal_mask: 0.192  loss_visible_mask: 0.210  loss_invisible_mask: 0.153  loss_rpn_cls: 0.011  loss_rpn_loc: 0.012  time: 0.3047  data_time: 0.0036  lr: 0.001499  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:17 d2.utils.events]: \u001b[0meta: 0:02:26  iter: 1019  total_loss: 1.032  loss_cls: 0.183  loss_box_reg: 0.254  loss_amodal_mask: 0.211  loss_visible_mask: 0.189  loss_invisible_mask: 0.146  loss_rpn_cls: 0.006  loss_rpn_loc: 0.013  time: 0.3050  data_time: 0.0034  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:24 d2.utils.events]: \u001b[0meta: 0:02:20  iter: 1039  total_loss: 1.217  loss_cls: 0.216  loss_box_reg: 0.256  loss_amodal_mask: 0.257  loss_visible_mask: 0.208  loss_invisible_mask: 0.177  loss_rpn_cls: 0.007  loss_rpn_loc: 0.014  time: 0.3054  data_time: 0.0157  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:31 d2.utils.events]: \u001b[0meta: 0:02:14  iter: 1059  total_loss: 1.183  loss_cls: 0.235  loss_box_reg: 0.253  loss_amodal_mask: 0.245  loss_visible_mask: 0.224  loss_invisible_mask: 0.154  loss_rpn_cls: 0.011  loss_rpn_loc: 0.017  time: 0.3057  data_time: 0.0035  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:36 d2.utils.events]: \u001b[0meta: 0:02:08  iter: 1079  total_loss: 1.170  loss_cls: 0.279  loss_box_reg: 0.242  loss_amodal_mask: 0.216  loss_visible_mask: 0.220  loss_invisible_mask: 0.144  loss_rpn_cls: 0.013  loss_rpn_loc: 0.019  time: 0.3055  data_time: 0.0035  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:43 d2.utils.events]: \u001b[0meta: 0:02:02  iter: 1099  total_loss: 0.903  loss_cls: 0.172  loss_box_reg: 0.229  loss_amodal_mask: 0.220  loss_visible_mask: 0.198  loss_invisible_mask: 0.112  loss_rpn_cls: 0.008  loss_rpn_loc: 0.011  time: 0.3056  data_time: 0.0033  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:49 d2.utils.events]: \u001b[0meta: 0:01:56  iter: 1119  total_loss: 0.921  loss_cls: 0.185  loss_box_reg: 0.199  loss_amodal_mask: 0.189  loss_visible_mask: 0.186  loss_invisible_mask: 0.118  loss_rpn_cls: 0.012  loss_rpn_loc: 0.010  time: 0.3056  data_time: 0.0035  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:19:55 d2.utils.events]: \u001b[0meta: 0:01:50  iter: 1139  total_loss: 1.108  loss_cls: 0.215  loss_box_reg: 0.208  loss_amodal_mask: 0.213  loss_visible_mask: 0.225  loss_invisible_mask: 0.127  loss_rpn_cls: 0.009  loss_rpn_loc: 0.016  time: 0.3056  data_time: 0.0035  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:20:01 d2.utils.events]: \u001b[0meta: 0:01:44  iter: 1159  total_loss: 1.081  loss_cls: 0.205  loss_box_reg: 0.262  loss_amodal_mask: 0.237  loss_visible_mask: 0.233  loss_invisible_mask: 0.208  loss_rpn_cls: 0.012  loss_rpn_loc: 0.021  time: 0.3058  data_time: 0.0035  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:20:08 d2.utils.events]: \u001b[0meta: 0:01:38  iter: 1179  total_loss: 0.783  loss_cls: 0.130  loss_box_reg: 0.132  loss_amodal_mask: 0.169  loss_visible_mask: 0.148  loss_invisible_mask: 0.108  loss_rpn_cls: 0.007  loss_rpn_loc: 0.010  time: 0.3059  data_time: 0.0037  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:20:14 d2.utils.events]: \u001b[0meta: 0:01:32  iter: 1199  total_loss: 1.195  loss_cls: 0.212  loss_box_reg: 0.230  loss_amodal_mask: 0.233  loss_visible_mask: 0.265  loss_invisible_mask: 0.162  loss_rpn_cls: 0.013  loss_rpn_loc: 0.012  time: 0.3059  data_time: 0.0041  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:20:20 d2.utils.events]: \u001b[0meta: 0:01:26  iter: 1219  total_loss: 0.973  loss_cls: 0.210  loss_box_reg: 0.200  loss_amodal_mask: 0.208  loss_visible_mask: 0.168  loss_invisible_mask: 0.151  loss_rpn_cls: 0.010  loss_rpn_loc: 0.012  time: 0.3060  data_time: 0.0037  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:20:26 d2.utils.events]: \u001b[0meta: 0:01:20  iter: 1239  total_loss: 1.007  loss_cls: 0.166  loss_box_reg: 0.220  loss_amodal_mask: 0.206  loss_visible_mask: 0.201  loss_invisible_mask: 0.136  loss_rpn_cls: 0.008  loss_rpn_loc: 0.014  time: 0.3062  data_time: 0.0040  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:20:33 d2.utils.events]: \u001b[0meta: 0:01:14  iter: 1259  total_loss: 0.829  loss_cls: 0.154  loss_box_reg: 0.193  loss_amodal_mask: 0.195  loss_visible_mask: 0.182  loss_invisible_mask: 0.070  loss_rpn_cls: 0.008  loss_rpn_loc: 0.014  time: 0.3063  data_time: 0.0039  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:20:39 d2.utils.events]: \u001b[0meta: 0:01:08  iter: 1279  total_loss: 1.078  loss_cls: 0.171  loss_box_reg: 0.192  loss_amodal_mask: 0.254  loss_visible_mask: 0.244  loss_invisible_mask: 0.139  loss_rpn_cls: 0.010  loss_rpn_loc: 0.014  time: 0.3062  data_time: 0.0035  lr: 0.001500  max_mem: 3100M\n",
      "\u001b[32m[03/01 23:20:45 d2.utils.events]: \u001b[0meta: 0:01:01  iter: 1299  total_loss: 1.047  loss_cls: 0.228  loss_box_reg: 0.224  loss_amodal_mask: 0.213  loss_visible_mask: 0.214  loss_invisible_mask: 0.115  loss_rpn_cls: 0.012  loss_rpn_loc: 0.013  time: 0.3062  data_time: 0.0035  lr: 0.001500  max_mem: 3100M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_orcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"amodal_coco_train\",)\n",
    "cfg.DATASETS.TEST = (\"amodal_coco_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80\n",
    "cfg.SOLVER.BASE_LR = 0.0015  # pick a good LR\n",
    "cfg.SOLVER.STEPS = (1400,)\n",
    "cfg.SOLVER.MAX_ITER = 1500 \n",
    "cfg.VIS_PERIOD = 500\n",
    "cfg.OUTPUT_DIR = \"orcnnCheckpoint\"\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set the testing threshold for this model\n",
    "import pdb; pdb.set_trace()\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=orcnnCheckpoint --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATASETS.TEST = (\"amodal_coco_val\",)\n",
    "cfg.DATASETS.TRAIN = (\"amodal_coco_train\",)\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9   # set the testing threshold for this model\n",
    "#  evaluate its performance using AP metric implemented in COCO API.\n",
    "from detectron2.evaluation import AmodalEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = AmodalEvaluator(\"amodal_coco_val\", cfg, False, output_dir=\"orcnnEvaluation\")\n",
    "val_loader = build_detection_test_loader(cfg, \"amodal_coco_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "import random\n",
    "from detectron2.data import DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_orcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.OUTPUT_DIR = \"orcnnCheckpoint\"\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9   # set the testing threshold for this model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"amodal_coco_val\",)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "dataset_dicts = DatasetCatalog.get(\"amodal_coco_val\")\n",
    "for d in random.sample(dataset_dicts, 1):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get(\"amodal_coco_val\"), scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d,\"invisible_mask\")\n",
    "    imshow(vis.get_image()[:, :, ::-1])\n",
    "#     import pdb;pdb.set_trace()\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"amodal_coco_val\"), \n",
    "                   scale=0.8, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"),'pred_invisible_masks')\n",
    "    imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
